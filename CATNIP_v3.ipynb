{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa20705f-9556-4268-9877-b3f29d488fa1",
   "metadata": {},
   "source": [
    "# CATNIP Analysis of light sheet imaging of whole-brain c-Fos immunostaining in constitutive PACAP-knockout and control PACAP-flox/flox mice\n",
    "\n",
    "The following Dandiset contains deconvolved and homogeneity corrected images of c-FOS immunostained whole mouse brains and the derivatives from the [CATNIP](https://github.com/snehashis-roy/CATNIP) analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c79c9",
   "metadata": {},
   "source": [
    "If running on [DandiHub](https://hub.dandiarchive.org/), please select the `dandi-dandi-openscope` kernel. Please note the `k3d` visualization will not work on DandiHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb73b3e-d934-48fc-886a-4a87c80bd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import fsspec\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a720efb-2900-4a4c-8340-d55ecc46817c",
   "metadata": {},
   "source": [
    "## Create a class for downloading files from CATNIP Dandiset\n",
    "\n",
    "DANDI Archive stores assests in S3 buckets and provides an API to access those clients. In order to facilitate downloading different assests from the CATNIP dataset we will construct a CatNabber class. CatNabber provides a way to easily download specific files from a DANDI dataset to a local directory, handling the retrieval of download URLs and checking for existing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde5099-409c-44bf-98ae-7f96aa09841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatNabber:\n",
    "    def __init__(self, dandiset_id: str, local_root: Path = Path(\"./catnip\")):\n",
    "        self.dandiset_id: str = dandiset_id\n",
    "        if not local_root.exists():\n",
    "            local_root.mkdir(exist_ok=True, parents=True)\n",
    "        self.local_root: Path = local_root\n",
    "\n",
    "\n",
    "    def _get_dandi_s3_uri(self, dandi_filepath: str) -> str:\n",
    "        with DandiAPIClient() as client:\n",
    "            asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(dandi_filepath)\n",
    "            s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "        return s3_url\n",
    "\n",
    "\n",
    "    def download_file(self, dandi_filepath: Path | str, force_redownload: bool = False) -> Path:\n",
    "        s3_uri: str = self._get_dandi_s3_uri(dandi_filepath=str(dandi_filepath))\n",
    "        local_filepath: Path = self.local_root.joinpath(dandi_filepath)\n",
    "        local_filepath.parent.mkdir(exist_ok=True, parents=True)\n",
    "        if local_filepath.exists() and force_redownload == False:\n",
    "            print(f\"{local_filepath} already exists. Skipping download\")\n",
    "            return local_filepath\n",
    "        try:\n",
    "            with fsspec.open(s3_uri, 'rb') as f_s3:\n",
    "                with open(local_filepath, 'wb') as f_local:\n",
    "                    f_local.write(f_s3.read())\n",
    "            print(f\"File '{s3_uri}' downloaded\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading file: {e}\")\n",
    "        return local_filepath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50690778-0794-4273-a917-c9813414cb83",
   "metadata": {},
   "source": [
    "## CATNIP Dandiset Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d2f77-9927-4cda-810a-0d891d00ccd4",
   "metadata": {},
   "source": [
    "The CATNIP dataset is in [BIDS format](https://bids.neuroimaging.io/index.html), specifically the [BIDS microscopy extension](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/microscopy.html). Part of the CATNIP dataset is a list samples and their corresponding participant ids. Below, we will instantiate a CatNabber class with the CATNIP dandiset id `001362` and download the `samples.tsv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3591d7-fb82-448f-92d7-cd96b6a67a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id=\"001362\"\n",
    "local_root: Path = Path(\"./catnip\")\n",
    "catnabber = CatNabber(dandiset_id, local_root)\n",
    "sample_path: str = \"samples.tsv\"\n",
    "local_sample: Path = catnabber.download_file(sample_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2298d71-66e0-4c1f-89d2-917cd9caa445",
   "metadata": {},
   "source": [
    "Below, we will show the samples in the CATNIP dandiset using a Pandas DataFrame. Each sample is an image stack of either the left or right hemisphere a participant's brain. Note, not all participants have both hemispheres imaged. The genotype of the participant is listed under the `pathology` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3992b8-9184-44cf-8193-96ade0102441",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples: pd.DataFrame = pd.read_csv(local_sample, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c09636-f16b-434d-a2c5-57440e877753",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b6180-57ca-4a61-a62b-35773ea7299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(samples)} in this dataset with {len(samples['participant_id'].unique())} participants\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0092e5-2d01-4ef6-9eab-2d92473fd4c7",
   "metadata": {},
   "source": [
    "## Deconvolved and Inhomogeneity Corrected Images\n",
    "\n",
    "The [BIDS microscopy extension](https://bids-specification.readthedocs.io/en/stable/modality-specific-files/microscopy.html) requires a strict directory structure. Using this structure we can gather a list of all the deconvolved and inhomogeneity corrected image stacks for each sample listed in the `samples.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbed05-e4fb-4f07-b3f7-a81d5c7a264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_images_paths: list[Path] = []\n",
    "for i, row in samples.iterrows():\n",
    "    corrected_image_parent: Path = Path(f\"{row['participant_id']}\").joinpath(\"micr\")\n",
    "    corrected_image_filename: str = row[\"participant_id\"] + \"_\" +  row[\"sample_id\"] + \"_SPIM.ome.btf\"\n",
    "    corrected_image_filepath: Path = corrected_image_parent.joinpath(corrected_image_filename)\n",
    "    corrected_images_paths.append(corrected_image_filepath)\n",
    "    print(f\"{i}: {corrected_image_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a2667-8e43-4f2d-8764-8af382f71fb7",
   "metadata": {},
   "source": [
    "Each of this image stacks are approximately 7 GB. These images can be downloaded from the S3 bucket to the DandiHub server hosting this notebook in a few minutes. Downloading them to a local machine can take considerably longer depending on your internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97268e2e-8706-4edb-9b8d-9246e165a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image = catnabber.download_file(corrected_images_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636cb20-fc9d-4eb8-acd7-1e3a51626d8a",
   "metadata": {},
   "source": [
    "Using DandiHub's large server, the entire image stack can easily be loaded into memory using the `tifffile` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485254c-e487-478f-b9e0-99e3eda3435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_array = tifffile.imread(local_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972eb1fd-26c6-44a7-8e57-c25eff6b4f88",
   "metadata": {},
   "source": [
    "For sample `sub-45424flox_sample-LeftHemiSphere` the resulting `im_array` has the dimensions ZYX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac5a7-e55c-40cf-a539-e9c97b445ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shape = im_array.shape\n",
    "im_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73761e29-2d84-48ff-be1f-b172ee2425dc",
   "metadata": {},
   "source": [
    "In order to display only planes with signal, we will trim off the blank planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f3c6d-baa1-4be5-91bf-fbf161c26eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_offset = -1\n",
    "plane = im_array[z_offset, :,:]\n",
    "while plane.sum() == 0:\n",
    "    z_offset -= 1\n",
    "    plane = im_array[z_offset, :, :]\n",
    "print(z_offset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b528df-d568-483c-b483-e0bdf1ff0338",
   "metadata": {},
   "source": [
    "## Visualizing the image stack\n",
    "\n",
    "Below the code takes 9 evenly spaced Z-planes from the stack excluding the blank planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5134b9d-910f-4dcf-a551-81ec4091eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the z-steps for the 9 images\n",
    "z_size, x_size, y_size = im_array.shape\n",
    "num_images = 9\n",
    "z_indices = np.linspace(0, z_size + z_offset, num_images, dtype=int)\n",
    "\n",
    "# Create a 3x3 subplot grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "fig.suptitle(f\"{samples['participant_id'][0]}: {samples['sample_id'][0]}\\nDeconvolved and N4 Corrected\")\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the z-indices and display the corresponding slices\n",
    "for i, z_index in enumerate(z_indices):\n",
    "    # Extract the 2D image slice\n",
    "    img_slice = im_array[z_index, :, :]\n",
    "\n",
    "    # Display the image in the corresponding subplot\n",
    "    axes[i].imshow(img_slice, cmap='gray')  # You can change 'gray' to other colormaps\n",
    "    axes[i].set_title(f'Z = {z_index}')\n",
    "    axes[i].axis('off')  # Turn off axis labels and ticks\n",
    "\n",
    "# Adjust layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Delete im_array to free up RAM\n",
    "del im_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be13771-b886-4f2e-b523-7f59bc3dc2ae",
   "metadata": {},
   "source": [
    "## Allen Mouse Brain Atlas Registration\n",
    "\n",
    "The deconvolved and inhomogeneity corrected images are registered to the [Allen Mouse Brain Atlas](https://mouse.brain-map.org/static/atlas). The resulting segmentation maps have the same dimensions as the corrected image stack. The maps are found in the `AtlasLabel` derivatives folder and are only approximately 50 MB. First we will download the segmentation map corresponding to sample `sub-45424flox_sample-LeftHemiSphere` shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e93b70-488f-4559-9625-e512f848590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandi_atlas_path: str = r\"derivatives/AtlasLabel/sub-45424flox/micr/sub-45424flox_sample-LeftHemisphere_space-orig_dseg.ome.btf\"\n",
    "local_atlas = catnabber.download_file(dandi_atlas_path)\n",
    "atlas_array = tifffile.imread(local_atlas)\n",
    "atlas_shape = atlas_array.shape\n",
    "print(f\"Image stack shape: {im_shape}, Atlas stack shape: {atlas_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dfe08-914c-4026-8fbf-d6e5777c7821",
   "metadata": {},
   "source": [
    "The CATNIP dandiset has a `dseg.tsv` file that indicates the brain region for each index value and a corresponding color hexvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf9c0e-707a-4402-9562-6061841117b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dandi_atlas_colormap_path: str = r\"derivatives/AtlasLabel/dseg.tsv\"\n",
    "local_atlas_colormap = catnabber.download_file(dandi_atlas_colormap_path)\n",
    "atlas_colormap_df: pd.DataFrame = pd.read_csv(local_atlas_colormap, sep='\\t')\n",
    "atlas_colormap_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b1a17-d5c4-442c-a14d-67d2605fce8c",
   "metadata": {},
   "source": [
    "Below, we convert the `color` values in the `dseg.tsv` file to a colormap. We must append black, `#000000`, to the beginning of the list for unmapped pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbf05a-b4b5-41a3-8d37-5b15ea1b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list: list[str] = [\"#000000\"] + atlas_colormap_df['color'].to_list()\n",
    "atlas_colormap: ListedColormap = ListedColormap(color_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c80f03-68aa-4258-bcc2-00718f31630c",
   "metadata": {},
   "source": [
    "## Visualizing the Atlas Segmentation Map\n",
    "\n",
    "Below we show the same planes fo the Atlas Segmentation Map as the corrected image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2476b-d81f-4939-b028-de79ae74a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the z-steps for the 9 images\n",
    "z_size, x_size, y_size = atlas_array.shape\n",
    "num_images = 9\n",
    "z_indices = np.linspace(0, z_size + z_offset, num_images, dtype=int)\n",
    "\n",
    "# Create a 3x3 subplot grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "fig.suptitle(f\"{samples['participant_id'][0]}: {samples['sample_id'][0]}\\nAllen Mouse Brain Atlas\")\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the z-indices and display the corresponding slices\n",
    "for i, z_index in enumerate(z_indices):\n",
    "    # Extract the 2D image slice\n",
    "    img_slice = atlas_array[z_index, :, :]\n",
    "\n",
    "    # Display the image in the corresponding subplot\n",
    "    axes[i].imshow(img_slice, cmap=atlas_colormap)  # You can change 'gray' to other colormaps\n",
    "    axes[i].set_title(f'Z = {z_index}')\n",
    "    axes[i].axis('off')  # Turn off axis labels and ticks\n",
    "\n",
    "# Adjust layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Delete the atlas_array to free up RAM\n",
    "del atlas_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097495b6-119c-4dbb-a423-1f790e41b49f",
   "metadata": {},
   "source": [
    "## c-FOS Signal Segmentation Masks\n",
    "\n",
    "c-FOS signals are segmented using range of threshold values. These result in a series of binary images. Below, we will iterate over the binary masks for plane 449 shown in the center of the plot above. The threshold values range from 4000 to 32000 with a step size of 2000 units. First, we must download all the binary image stacks for sample `sub-45424flox_sample-LeftHemisphere`. Each image stack file is between 7 and 21 MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28b59d-fed1-4efd-a88e-653072d16d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_map: dict[int, Path] = {}\n",
    "for thresh_int in range(4000, 34000, 2000):\n",
    "    thresh_str: str = str(thresh_int).zfill(6)\n",
    "    dandi_atlas_path: str = f\"derivatives/FastRadialSymmetryTransformSegmentation/sub-45424flox/micr/sub-45424flox_sample-LeftHemisphere_acq-{thresh_str}_SPIM.ome.btf\"\n",
    "    local_path: Path = catnabber.download_file(dandi_atlas_path)\n",
    "    binary_map[thresh_int] = local_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b9347-ddd5-4d2c-92b7-b5a442a8523e",
   "metadata": {},
   "source": [
    "## Visualizing the Segmentastion Masks\n",
    "\n",
    "In order to compare the masks of the same plan across different thresholds, we will iterate over the images and only show plan `449` in the subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fa361-9ba0-4323-bf2c-30625a7c5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x5 subplot grid\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "fig.suptitle(f\"{samples['participant_id'][0]}: {samples['sample_id'][0]}\\nBinary c-FOS signals\")\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the z-indices and display the corresponding slices\n",
    "for i, thresh_int in enumerate(range(4000, 34000, 2000)):\n",
    "\n",
    "    # Extract the 2D image slice\n",
    "    binary_array = tifffile.imread(binary_map[thresh_int])\n",
    "    binary_image = binary_array[449,:,:]\n",
    "    del binary_array\n",
    "    \n",
    "\n",
    "    # Display the image in the corresponding subplot\n",
    "    axes[i].imshow(binary_image, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i].set_title(f'Threshold={thresh_int}')\n",
    "    axes[i].axis('off')  # Turn off axis labels and ticks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa5461-0d78-453b-a7dc-e776cad7b26b",
   "metadata": {},
   "source": [
    "## Quantification of Signal by Region\n",
    "\n",
    "The number of c-FOS signals were counted per region for each threshold value. These are present in the Dandiset as TSV files in the `FastRadialSymmetryTransformSegmentationCounts` derivative folder. Below are the counts for sample `sub-45424flox_sample-LeftHemisphere` at a threshold vlaue of `4000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1c0c8-cf20-4bb5-8d9a-ec8ddadf5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_path: str = f\"derivatives/FastRadialSymmetryTransformSegmentationCounts/sub-45424flox/micr/sub-45424flox_sample-LeftHemisphere_acq-004000_SPIM.tsv\"\n",
    "local_counts: Path = catnabber.download_file(counts_path)\n",
    "counts: pd.DataFrame = pd.read_csv(local_counts, sep='\\t', index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4184-8e32-4926-939f-b14fb17d6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5500c-a9d1-4294-b745-0a38b7b70570",
   "metadata": {},
   "source": [
    "## Heatmaps of the Cell Counts\n",
    "\n",
    "Heatmaps of the cell counts were generated the cell counts. These heatmaps are downsampled and can be viewed as volumes using the `k3d` module on DandiHub or on a Jupyter Notebook. First, we download the image to the server using CatNabber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd06467-d163-43f0-95ed-59ced26ace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_image = catnabber.download_file(\"derivatives/HeatmapsAtlasSpace/sub-45424flox/micr/sub-45424flox_sample-LeftHemisphere_acq-heatmap_res-25um_SPIM.ome.btf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43214430-4049-42e2-a28d-214bf81b58f0",
   "metadata": {},
   "source": [
    "Now we load the image into memory. Note the much smaller size of the heatmap array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e1d28-afa5-4162-bb7c-394212ea8f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_array = tifffile.imread(heatmap_image)\n",
    "heatmap_array.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8706d4-e271-4b22-ba99-bb39f8b06177",
   "metadata": {},
   "source": [
    "## Volume Visualization using K3D in Jupyter Notebook\n",
    "\n",
    "### K3D no longer working on DANDI HUB\n",
    "\n",
    "On DandiHub, the Jupyter server no longer has the [k3d Jupyter Extension](https://github.com/K3D-tools/K3D-jupyter) installed. This prevents 3D visualization of the heatmap array. Please view `README.md` to install a local Jupyter Notebook server for k3d visualizations.\n",
    "\n",
    "\n",
    "The volume can be rotated, zoomed, and further manipulated using the `K3D panel` in the top right corner. Please see the [panel user guide](https://k3d-jupyter.org/user/panel.html). Finally, we use [Google's Turbo](https://research.google/blog/turbo-an-improved-rainbow-colormap-for-visualization/) colormap to provide contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccb7b6-0253-4666-8644-9fc309c9307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "from k3d.colormaps import matplotlib_color_maps\n",
    "\n",
    "k3d.factory.volume(volume=heatmap_array, color_map=matplotlib_color_maps.Turbo)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
